from typing import Dict, Any, Union, List, Callable, Optional
import zmq, traceback, time, logging, xml, socket, abc, dask, threading
from edask.workflow.module import edasOpManager
from edask.process.task import Job
from edask.workflow.data import EDASDataset
from dask.distributed import Client, Future, LocalCluster
from edask.util.logging import EDASLogger
from edask.portal.cluster import EDASCluster
from distributed.publish import Datasets
from distributed.security import Security
from edask.config import EdaskEnv
import random, string, os, queue, datetime, atexit, multiprocessing, errno, uuid
from threading import Thread
import xarray as xa
from collections import defaultdict
try:
    from cytoolz import first, groupby, merge, valmap, keymap
except ImportError:
    from toolz import first, groupby, merge, valmap, keymap
try:
    from dask.delayed import single_key
except ImportError:
    single_key = first
from tornado.gen import TimeoutError
from tornado.locks import Semaphore

from distributed.utils import ( ignoring,  no_default, PeriodicCallback, LoopRunner, parse_timedelta )

class ExecHandlerBase:
    __metaclass__ = abc.ABCMeta

    def __init__(self, clientId: str, jobId: str, **kwargs ):
        self.logger = EDASLogger.getLogger()
        self.clientId = clientId
        self.jobId = jobId
        self.cacheDir = kwargs.get( "cache", "/tmp")
        self.workers = kwargs.get( "workers", 1 )
        self.completed = 0
        self.start_time = time.time()
        self.filePath = self.cacheDir + "/" + Job.randomStr(6) + ".nc"

    def updateStartTime( self):
        self.start_time = time.time()

    def getExpDir(self, proj: str, exp: str ) -> str:
        expDir =  self.cacheDir + "/experiments/" + proj + "/" + exp
        return self.mkDir( expDir )

    def getExpFile(self, proj: str, exp: str, name: str, type: str = "nc" ) -> str:
        expDir =  self.getExpDir( proj, exp )
        return expDir + "/" + name + "-" + Job.randomStr(6) + "." + type

    @abc.abstractmethod
    def successCallback(self, resultFuture: Future): pass

    @abc.abstractmethod
    def failureCallback(self, ex: Exception): pass

    @abc.abstractmethod
    def processResult(self, result: EDASDataset  ): pass

    @abc.abstractmethod
    def iterationCallback( self, resultFuture: Future ): pass

    def mkDir(self, dir: str ) -> str:
        try:
            os.makedirs(dir)
        except OSError as e:
            if e.errno != errno.EEXIST: raise
        return dir

class SubmissionThread(Thread):

    def __init__(self, job: Job, resultHandler: ExecHandlerBase):
        Thread.__init__(self)
        self.job = job
        self.resultHandler = resultHandler
        self.logger =  EDASLogger.getLogger()

    def run(self):
        start_time = time.time()
        try:
            self.logger.info( "Running workflow for requestId " + self.job.requestId)
            result = edasOpManager.buildTask( self.job )
            self.logger.info( "Completed workflow in time " + str(time.time()-start_time) )
            self.resultHandler.processResult( result )
        except Exception as err:
            self.logger.error( "Execution error: " + str(err))
            self.logger.error( traceback.format_exc() )
            self.resultHandler.failureCallback(err)

class ExecHandler(ExecHandlerBase):

    def __init__( self, clientId: str, _job: Job, portal, **kwargs ):
        from edask.portal.base import EDASPortal
        super(ExecHandler, self).__init__(clientId, _job.requestId, **kwargs)
        self.portal: EDASPortal = portal
        self.client = portal.processManager.client
        self.sthread = None
        self._processResults = True
        self.results: List[EDASDataset] = []
        self.job = _job

    def execJob(self, job: Job ) -> SubmissionThread:
        self.sthread = SubmissionThread(job,self)
        self.sthread.start()
        self.logger.info( " ----------------->>> Submitted request for job " + job.requestId )
        return self.sthread

    def getResult(self, timeout=None):
        self._processResults = False
        self.sthread.join(timeout)
        return self.mergeResults()

    def processResult( self, result: EDASDataset ):
        self.results.append( result )
        self._processFinalResult( )
        if self.portal: self.portal.removeHandler( self.clientId, self.jobId )

    def successCallback(self, resultFuture: Future):
      status = resultFuture.status
      if status == "finished":
          self.results.append( resultFuture.result() )
          self.logger.info( " Completed computation " + self.jobId + " in " + str(time.time() - self.start_time) + " seconds" )
          self._processFinalResult( )
      else:
          self.failureCallback( resultFuture.result() )
      if self.portal: self.portal.removeHandler( self.clientId, self.jobId )

    def _processFinalResult( self ):
        assert len(self.results), "No results generated by request"
        if self._processResults:
            result = self.mergeResults()
            try:
                savePath = result.save()
                if self.portal:
                    sendData = self.job.runargs.get( "sendData", "true" ).lower().startswith("t")
                    self.portal.sendFile( self.clientId, self.jobId, result.id, savePath, sendData )
                else:
                    self.printResult(savePath)
            except Exception as err:
                self.logger.error( "Error processing final result: " + str(err) )
                self.logger.info(traceback.format_exc())
                self.portal.sendFile(self.clientId, self.jobId, result.id, "", False )

    def printResult( self, filePath: str ):
        dset = xa.open_dataset(filePath)
        print( str(dset) )

    def mergeResults(self) -> EDASDataset:
        mergeMethod: str = self.results[0]["merge"]
        if mergeMethod is None: return EDASDataset.merge( self.results )
        mergeToks = mergeMethod.split(":")
        return self.getBestResult( mergeToks[0].strip().lower(), mergeToks[1].strip().lower() )

    def getBestResult(self, method: str, parm: str )-> EDASDataset:
        bestResult = None
        bestValue = None
        values = []
        for result in self.results:
            pval = result[parm]
            assert pval, "Error, parameter '{}' not defined in dataset".format( parm )
            values.append(float(pval))
            if bestResult is None or self.compare( method, float(pval), bestValue ):
                bestResult = result
                bestValue = float(pval)
        return bestResult

    def compare(self, method: str, current: float, threshold: float ):
        if method == "min": return current < threshold
        if method == "max": return current > threshold
        raise Exception( "Unknown comparison method: " + method )

    def getTbStr(self, ex ) -> str:
        if ex.__traceback__  is None: return ""
        tb = traceback.extract_tb( ex.__traceback__ )
        return " ".join( traceback.format_list( tb ) )

    def getErrorReport(self, ex ):
        errMsg = getattr( ex, 'message', repr(ex) )
        return errMsg + ">~>" +  str( self.getTbStr(ex) )

    def failureCallback(self, ex: Exception ):
        try: error_message = self.getErrorReport( ex )
        except: error_message = repr(ex)
        if self.portal:
            self.portal.sendErrorReport( self.clientId, self.jobId, error_message )
            self.portal.removeHandler( self.clientId, self.jobId )
        else:
            self.logger.error( error_message )

    def iterationCallback( self, resultFuture: Future ):
      status = resultFuture.status
      if status == "finished":
          self.completed = self.completed + 1
          result: EDASDataset = resultFuture.result()
          self.results.append(result)
      else:
          try:                      self.failureCallback( Exception("status = " + status + "\n>~>" + str( traceback.format_tb(resultFuture.traceback(60)) ) ) )
          except TimeoutError:
              try:                  self.failureCallback( Exception("status = " + status + ", Exception = " + str( resultFuture.exception(60) )  ) )
              except TimeoutError:
                                    self.failureCallback( Exception("status = " + status  ) )
      if self.completed == self.workers:
        self._processFinalResult()
        if self.portal:
            self.portal.removeHandler( self.clientId, self.jobId )

class GenericProcessManager:
  __metaclass__ = abc.ABCMeta

  @abc.abstractmethod
  def submitProcess(self, service: str, job: Job, resultHandler: ExecHandler)-> str: pass

  @abc.abstractmethod
  def getResult( self, service: str, resultId: str ): pass

  @abc.abstractmethod
  def getResultStatus( self, service: str, resultId: str ): pass

  @abc.abstractmethod
  def hasResult( self, service: str, resultId: str )-> bool: pass

  @abc.abstractmethod
  def serverIsDown( self )-> bool: pass

  @abc.abstractmethod
  def term(self): pass

  def waitUntilJobCompletes( self, service: str, resultId: str  ):
    while( not self.hasResult(service,resultId) ): time.sleep(0.5)

class EDASClient(Client):

    def __init__(self, cluster: EDASCluster, loop=None, timeout=no_default,
                     set_as_default=True, scheduler_file=None,
                     security=None, asynchronous=False,
                     name=None, heartbeat_interval=None,
                     serializers=None, deserializers=None,
                     extensions=[], direct_to_workers=False,
                     **kwargs ):
        self.logger = EDASLogger.getLogger()
        self.cluster = cluster
        self.scheduler = cluster.scheduler
        if timeout == no_default:
            timeout = dask.config.get('distributed.comm.timeouts.connect')
        if timeout is not None:
            timeout = parse_timedelta(timeout, 's')
        self._timeout = timeout

        self.futures = dict()
        self.refcount = defaultdict(lambda: 0)
        self.coroutines = []
        if name is None:
            name = dask.config.get('client-name', None)
        self.id = type(self).__name__ + ('-' + name + '-' if name else '-') + str(uuid.uuid1(clock_seq=os.getpid()))
        self.generation = 0
        self.status = 'newly-created'
        self._pending_msg_buffer = []
        self.extensions = {}
        self.scheduler_file = scheduler_file
        self._startup_kwargs = kwargs
        self._scheduler_identity = {}
        # A reentrant-lock on the refcounts for futures associated with this
        # client. Should be held by individual operations modifying refcounts,
        # or any bulk operation that needs to ensure the set of futures doesn't
        # change during operation.
        self._refcount_lock = threading.RLock()
        self.datasets = Datasets(self)
        self._serializers = serializers
        if deserializers is None:
            deserializers = serializers
        self._deserializers = deserializers
        self.direct_to_workers = direct_to_workers

        self._gather_semaphore = Semaphore(5)
        self._gather_keys = None
        self._gather_future = None

        # Communication
        self.security = security or Security()
        self.scheduler_comm = None
        assert isinstance(self.security, Security)

        if name == 'worker':
            self.connection_args = self.security.get_connection_args('worker')
        else:
            self.connection_args = self.security.get_connection_args('client')

        with ignoring(AttributeError):
            loop = self.cluster.loop

        self._connecting_to_scheduler = False
        self._asynchronous = asynchronous
        self._should_close_loop = not loop
        self._loop_runner = LoopRunner(loop=loop, asynchronous=asynchronous)
        self.loop = self._loop_runner.loop

        if heartbeat_interval is None:
            heartbeat_interval = dask.config.get('distributed.client.heartbeat')
        heartbeat_interval = parse_timedelta(heartbeat_interval, default='ms')

        self._periodic_callbacks = dict()
        self._periodic_callbacks['scheduler-info'] = PeriodicCallback(self._update_scheduler_info, 2000, io_loop=self.loop)
        self._periodic_callbacks['heartbeat'] = PeriodicCallback( self._heartbeat, heartbeat_interval * 1000,  io_loop=self.loop )

        self._start_arg = cluster
        if set_as_default:
            self._set_config = dask.config.set(scheduler='dask.distributed', shuffle='tasks')

        self._stream_handlers = {
            'key-in-memory': self._handle_key_in_memory,
            'lost-data': self._handle_lost_data,
            'cancelled-key': self._handle_cancelled_key,
            'task-retried': self._handle_retried_key,
            'task-erred': self._handle_task_erred,
            'restart': self._handle_restart,
            'error': self._handle_error
        }

        self._state_handlers = {
            'memory': self._handle_key_in_memory,
            'lost': self._handle_lost_data,
            'erred': self._handle_task_erred
        }

        super(Client, self).__init__(connection_args=self.connection_args, io_loop=self.loop, serializers=serializers, deserializers=deserializers)

        for ext in extensions:
            ext(self)

        self.start(timeout=timeout)
        from distributed.recreate_exceptions import ReplayExceptionClient
        ReplayExceptionClient(self)

    def _update_scheduler_info(self):
        if self.status not in ('running', 'connecting'):
            return
        try:
            self._scheduler_identity = self.scheduler.identity()
        except EnvironmentError:
            self.logger.debug("Not able to query scheduler for identity")

class ProcessManager(GenericProcessManager):

  def __init__( self, serverConfiguration: Dict[str,str], cluster: EDASCluster = None ):
      self.config = serverConfiguration
      self.logger =  EDASLogger.getLogger()
      self.submitters = []
      if cluster is not None:
          self.logger.info( "Initializing Dask cluster with cluster" )
          self.client = EDASClient(cluster)
      else:
          nWorkers = int( self.config.get("dask.nworkers",multiprocessing.cpu_count()) )
          self.logger.info( "Initializing Local Dask cluster with {} workers".format(nWorkers) )
          self.client = Client( LocalCluster( n_workers=nWorkers ) )
          self.client.submit( lambda x: edasOpManager.buildIndices( x ), nWorkers )

  def term(self):
      self.client.close()

  def runProcess( self, job: Job ) -> EDASDataset:
    start_time = time.time()
    try:
        self.logger.info( "Running workflow for requestId " + job.requestId)
        result = edasOpManager.buildTask( job )
        self.logger.info( "Completed workflow in time " + str(time.time()-start_time) )
        return result
    except Exception as err:
        self.logger.error( "Execution error: " + str(err))
        traceback.print_exc()


  def submitProcess(self, service: str, job: Job, resultHandler: ExecHandler):
      submitter: SubmissionThread = SubmissionThread( job, resultHandler )
      self.submitters.append( submitter )
      submitter.start()


